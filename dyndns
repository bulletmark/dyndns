#!.venv/bin/python
"Update external IP v4 and/or v6 addresses to dynamic DNS servers."
# Mark Blakeney, Nov 2016.

from __future__ import annotations

import argparse
import asyncio
import json
import os
import re
import sys
import time
from collections import deque
from hashlib import sha256 as hasher
from ipaddress import IPv4Address, IPv6Address
from pathlib import Path

from aiohttp import ClientSession as Session

if sys.version_info >= (3, 11):
    import tomllib
else:
    import tomli as tomllib

import convtime

PROG = Path(__file__).stem
CACHEDIR = Path(os.getenv('XDG_CACHE_HOME', '~/.cache'), PROG).expanduser()
CONFFILE = Path(os.getenv('XDG_CONFIG_HOME', '~/.config'), f'{PROG}.toml').expanduser()
IPCACHE = CACHEDIR / 'ipaddrs'
URLCACHE = CACHEDIR / 'urls'

ADDRESS_TYPES = {'ipv4': IPv4Address, 'ipv6': IPv6Address}
ADDRESS_TXT = ' or '.join(ADDRESS_TYPES)
OFFSTATES = {'off', 'no', 'none', 'false'}

# Process command line options
opt = argparse.ArgumentParser(description=__doc__)
opt.add_argument('-v', '--verbose', action='store_true', help='verbose output')
opt.add_argument(
    '-i', '--ignore-cache', action='store_true', help='ignore cache for startup'
)
opt.add_argument(
    '-c',
    '--conf',
    default=str(CONFFILE),
    help=f'configuration file, default = {CONFFILE}',
)
args = opt.parse_args()

conffile = Path(args.conf)
if not conffile.exists():
    sys.exit(f'ERROR: Configuration file "{conffile}" does not exist.')

# Get configuration values
with conffile.open('rb') as fp:
    conf = tomllib.load(fp)

tconf = conf.get('times', {})
poll_period = int(convtime.tosec(tconf.get('poll_period', '10m')))
force_period = int(convtime.tosec(tconf.get('force_period', '24h'))) * 1000_000_000


def log(msg: str) -> None:
    "Log message to stdout"
    print(msg, flush=True)


def logerr(msg: str) -> None:
    "Log message to stderr"
    print(msg, file=sys.stderr, flush=True)


async def urlget(session: Session, url: str) -> str | None:
    "Fetch given url"
    try:
        async with session.get(url) as response:
            response.raise_for_status()
            txt = await response.text()
    except Exception as e:
        logerr(str(e))
        return None

    return txt.strip() if txt else ''


class IPSERVER:
    types = set()

    def __init__(self, name: str, servers: list[str]) -> None:
        "Create IP address type to poll servers"
        self.address_type = ADDRESS_TYPES.get(name)
        if not self.address_type:
            sys.exit(f'ERROR: Invalid server IP type {name} configured.')

        if len(servers) < 1:
            sys.exit(f'ERROR: Must define at least 1 {name} server.')

        self.name = name
        self.servers = deque(servers)
        self.types.add(name)
        self.file = IPCACHE / name
        self.session = None
        self.ip = None
        self.failed = False

        # Load fetch values from last time we ran
        if self.file.exists() and not args.ignore_cache:
            try:
                self.ip = self.file.read_text()
            except Exception:
                self.file.unlink()

        log(f'Configured ADDRESS {name}: {servers}')

    def ip_valid(self, ipstr: str | None) -> bool:
        "Return True if passed IP address is valid"
        if not ipstr or not self.address_type:
            return False

        try:
            _ = self.address_type(ipstr)
        except Exception:
            return False

        return True

    async def get_ip(self) -> IPSERVER | None:
        "Return (name, ipaddress) if we fetch IP address successfully"
        # Set session handle 1st time (must be done in async func)
        if not self.session:
            self.session = Session()
            first = True
        else:
            first = False

        for index, url in enumerate(self.servers):
            ip = await urlget(self.session, url)
            if not self.ip_valid(ip):
                if not self.failed:
                    logerr(f'Failed to fetch {self.name} address from {url} (#{index})')
            else:
                # Rotate server list so that last good is first
                self.servers.rotate(-index)

                if ip and ip != self.ip:
                    log(f'{self.name} address changed from {self.ip} to {ip} ({url})')
                    self.ip = ip
                    self.file.write_text(ip)

                if args.verbose or first or self.failed:
                    log(f'Fetched {self.name} address {ip} from {url} (#{index})')

                self.failed = False
                return self

        if not self.failed:
            logerr(f'Failed to fetch {self.name} address from any server')
            self.failed = True

        return None


class URL:
    allneeds = set()

    def __init__(self, conf: dict[str, str]) -> None:
        "Create URL for sending to dyndns server"
        self.url = conf.get('url')
        if not self.url:
            sys.exit('ERROR: url not defined')

        # Record which IP address types we need for this URL
        self.needs = {k for k in ADDRESS_TYPES if f'<{k}>' in self.url}

        auto = conf.get('auto', 'off')
        auto = 'false' if auto is False else auto.lower()
        if auto not in OFFSTATES:
            for k in ADDRESS_TYPES:
                if k == auto:
                    self.needs.add(k)
                    break
            else:
                sys.exit(f'ERROR: url {self.url}, auto={auto} not valid.')

        if not self.needs:
            sys.exit(f'ERROR: url {self.url} must specify either {ADDRESS_TXT}')

        # Sanity check configuration
        for key in self.needs:
            if key not in IPSERVER.types:
                sys.exit(
                    f'ERROR: URL {self.url} needs {key} but {key} server '
                    'is not configured.'
                )

        response = conf.get('response')

        response_l = []
        if isinstance(response, str):
            response_l.append(response)
        elif isinstance(response, list):
            response_l.extend(response)
        else:
            sys.exit(f'ERROR: url {self.url}, response must be string or list.')

        self.response = [re.compile(s) for s in response_l]
        self.allneeds |= self.needs
        self.file = URLCACHE / hasher(self.url.encode()).hexdigest()
        self.session = None
        self.time = None
        self.failed = set()
        self.values = {}

        # Add url to cache save data merely for ID/comment
        self.cache_data = {'url': self.url}

        # Load sent values from last time we ran
        if self.file.exists() and not args.ignore_cache:
            try:
                with self.file.open() as fp:
                    self.values = json.load(fp)
            except Exception:
                self.file.unlink()
            else:
                self.time = self.file.stat().st_mtime_ns + force_period
                # Remove url (comment) field
                if 'url' in self.values:
                    del self.values['url']

        needs = ' and '.join(self.needs)
        log(f'Configured URL {self.url}: {needs}')

    async def set_ips(self, now: int, values: dict[str, str]) -> None:
        "Send IP addresses to this dyndns server"
        failed = self.needs - set(values)

        # Strip out only the values we need for this URL and use
        # previous values for those that are failed
        values = {k: values.get(k, self.values.get(k, '?')) for k in self.needs}

        if failed != self.failed:
            if failed:
                missing = ' and '.join(failed)
                log(f'url {self.url} missing {missing} data')
            else:
                recovered = ' and '.join(self.failed)
                log(f'url {self.url} recovered {recovered} data')

            self.failed = failed

        # Only send on change or if "force_period" is due
        change = values != self.values
        if not change and self.time and now < self.time:
            return

        # Substitute IPs into URL
        if not (url := self.url):
            return

        for key, value in values.items():
            url = url.replace(f'<{key}>', value)

        # Set session handle 1st time (must be done in async func)
        if not self.session:
            self.session = Session()

        # Send to dyndns server
        response = await urlget(self.session, url)
        if response is not None:
            if not self.response or any(s.search(response) for s in self.response):
                # Update successful, save new record to cache file
                self.cache_data.update(values)
                with self.file.open('w') as fp:
                    json.dump(self.cache_data, fp)

                self.values = values
                self.time = now + force_period
                if args.verbose or change:
                    if response:
                        response = f': {response}'
                    types = ' & '.join(self.needs)
                    log(f'Sent {url} for {types}{response}')
            else:
                logerr(f'URL {url} responded with error: {response}')
        else:
            logerr(f'Failed to send {url}')


async def main() -> None:
    "Main code"
    IPCACHE.mkdir(parents=True, exist_ok=True)
    URLCACHE.mkdir(parents=True, exist_ok=True)

    # Build list of IP address servers
    servers = {k: IPSERVER(k, v) for k, v in conf.get('servers', {}).items()}

    if len(servers) < 1:
        sys.exit(
            f'ERROR: Must define at least one IP address {ADDRESS_TXT} server list.'
        )

    # Build list of dyndns urls
    urls = [URL(c) for c in conf.get('urls', {})]

    if len(urls) < 1:
        sys.exit('ERROR: Must define at least one url.')

    # Now discard IP address types we dont actually need after reading URLs
    servers = [servers[k] for k in URL.allneeds]

    while True:
        # Get IP addresses in parallel
        ips = await asyncio.gather(*(s.get_ip() for s in servers))
        ips_vals = {s.name: s.ip for s in ips if s and s.ip}
        now = time.time_ns()

        # Got all addresses, now send to dyndns URLs in parallel
        await asyncio.gather(*(u.set_ips(now, ips_vals) for u in urls))
        await asyncio.sleep(poll_period)


asyncio.run(main())
